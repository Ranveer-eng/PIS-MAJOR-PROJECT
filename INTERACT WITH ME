import face_recognition
import cv2, os
import numpy as np
import pyttsx3
# Get a reference to webcam #0 (the default one)
video_capture = cv2.VideoCapture(0)
import serial

#serial.PosixPollSerial
#all images
#images = os.listdir('all_images')


# Load a sample picture and learn how to recognize it.
obama_image = face_recognition.load_image_file("ranveer1.jpg")
obama_face_encoding = face_recognition.face_encodings(obama_image)[0]

# Load a second sample picture and learn how to recognize it.
biden_image = face_recognition.load_image_file("puneet1.jpg")
biden_face_encoding = face_recognition.face_encodings(biden_image)[0]

# Load a third sample picture and learn how to recognise it.
sachin_image = face_recognition.load_image_file("sachin1.jpg")
sachin_face_encoding = face_recognition.face_encodings(sachin_image)[0]


# Create arrays of known face encodings and their names
known_face_encodings = [
    obama_face_encoding,
    biden_face_encoding,
    sachin_face_encoding
    

]
known_face_names = [
    "Ranveer",
    "Puneet",
    "Sachin"
    
]

# Initialize some variables
face_locations = []
face_encodings = []
face_names = []
process_this_frame = True

while True:
    # Grab a single frame of video
    ret, frame = video_capture.read()

    # Resize frame of video to 1/4 size for faster face recognition processing
    small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)

    # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)
    rgb_small_frame = small_frame[:, :, ::-1]
    name = "Jaanu"

    # Only process every other frame of video to save time
    if process_this_frame:
        # Find all the faces and face encodings in the current frame of video
        face_locations = face_recognition.face_locations(rgb_small_frame)
        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)

        face_names = []
        for face_encoding in face_encodings:
            # See if the face is a match for the known face(s)
            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)
            name = "Unknown"

            # # If a match was found in known_face_encodings, just use the first one.
            # if True in matches:
            #     first_match_index = matches.index(True)
            #     name = known_face_names[first_match_index]

            # Or instead, use the known face with the smallest distance to the new face
            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)
            best_match_index = np.argmin(face_distances)
            if matches[best_match_index]:
                name = known_face_names[best_match_index]

            face_names.append(name)

    process_this_frame = not process_this_frame


    # Display the results
    if name in known_face_names:
        for (top, right, bottom, left), name in zip(face_locations, face_names):
            # Scale back up face locations since the frame we detected in was scaled to 1/4 size
            top *= 4
            right *= 4
            bottom *= 4
            left *= 4

            # Draw a box around the face
            cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)

            # Draw a label with a name below the face
            cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)
            font = cv2.FONT_HERSHEY_DUPLEX
            cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)
            
            engine = pyttsx3.init()
            engine.say("Hi"+name)
            engine.runAndWait()
        break
        
    # Display the resulting image
    cv2.imshow('I am looking at Your face', frame)

    # Hit 'q' on the keyboard to quit!
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release handle to the webcam
video_capture.release()
cv2.destroyAllWindows()



# importing speech recognition package from google api 
import speech_recognition as sr 
import playsound # to play saved mp3 file 
from gtts import gTTS # google text to speech 
import os # to save/open files 
import wolframalpha # to calculate strings into formula 
from selenium import webdriver # to control browser operations 
from PIL import Image
image = Image.open('puneet1.jpg')


num = 1
def assistant_speaks(output): 
    global num 

    # num to rename every audio file 
    # with different name to remove ambiguity 
    num += 1
    print("Zayikaa : ", output) 

    toSpeak = gTTS(text = output, lang ='en', slow = False) 
    # saving the audio file given by google text to speech 
    file = str(num)+".mp3"
    toSpeak.save(file) 
	
    # playsound package is used to play the same file. 
    playsound.playsound(file, True) 
    os.remove(file) 



def get_audio(): 

    rObject = sr.Recognizer() 
    audio = '' 

    with sr.Microphone() as source: 
        print("Speak...") 
		
        # recording the audio using speech recognition 
        audio = rObject.listen(source, phrase_time_limit = 5) 
    print("Stop.") # limit 5 secs 

    try: 

        text = rObject.recognize_google(audio, language ='en-US') 
        print("You : ", text) 
        return text 

    except: 

        assistant_speaks("Could not understand your audio, PLease try again !") 
        return 0


def search_web(input): 

    driver = webdriver.Firefox() 
    driver.implicitly_wait(1) 
    driver.maximize_window() 

    if 'youtube' in input.lower(): 

        assistant_speaks("Opening in youtube") 
        indx = input.lower().split().index('youtube') 
        query = input.split()[indx + 1:] 
        driver.get("http://www.youtube.com/results?search_query =" + '+'.join(query)) 
        return

    elif 'wikipedia' in input.lower(): 

        assistant_speaks("Opening Wikipedia") 
        indx = input.lower().split().index('wikipedia') 
        query = input.split()[indx + 1:] 
        driver.get("https://en.wikipedia.org/wiki/" + '_'.join(query)) 
        return

    else: 

        if 'google' in input: 

            indx = input.lower().split().index('google') 
            query = input.split()[indx + 1:] 
            driver.get("https://www.google.com/search?q =" + '+'.join(query)) 

        elif 'search' in input: 

            indx = input.lower().split().index('google') 
            query = input.split()[indx + 1:] 
            driver.get("https://www.google.com/search?q =" + '+'.join(query)) 

        else: 

            driver.get("https://www.google.com/search?q =" + '+'.join(input.split())) 

        return


# function used to open application 
# present inside the system. 
def open_application(input): 

    if "chrome" in input: 
        assistant_speaks("Google Chrome") 
        os.startfile('C:\Program Files (x86)\Google\Chrome\Application\chrome.exe') 
        return

    elif "firefox" in input or "mozilla" in input: 
        assistant_speaks("Opening Mozilla Firefox") 
        os.startfile('C:\Program Files\Mozilla Firefox\\firefox.exe') 
        return

    elif "word" in input: 
        assistant_speaks("Opening Microsoft Word") 
        os.startfile('C:\ProgramData\Microsoft\Windows\Start Menu\Programs\Microsoft Office 2013\\Word 2013.lnk') 
        return

    elif "excel" in input: 
        assistant_speaks("Opening Microsoft Excel") 
        os.startfile('C:\ProgramData\Microsoft\Windows\Start Menu\Programs\Microsoft Office 2013\\Excel 2013.lnk') 
        return

    else: 

        assistant_speaks("Application not available") 
        return


puneet = {
    "friend name":"I have two friends, Sachin and Ranveer",
    "roll number":"two zero one nine zero eight one",
    "father":"Subhash chandra",
    "age":"eighteen years",
    "date of birth":"twenty fifth january two thousands two",
    "where do you study":"Indraprasath institute of information technology Delhi",
    "do you have any girlfriend":"No, I am single",
    "what do you want to become in life":"Software Engineer, and I also want to work in Google",
    "what are your hobbies":"playing PUBJEE MOBILE",
    "favourite subject":"mathematics",
    "favourite food":"raajma chaawal",
    "favourite actor":"Akshay kumar",
    "favourite actress":"anushka sharma",
    "room number":"nine zero five",
    "kya chal raha hai":"Theek chal raha hai",
    "kaisa hai bhai":"theek hu"
    }


def talk_audio():
    text1 = get_audio().lower()
    return text1


def process_text(input): 
    try: 
        if 'search' in input or 'play' in input: 
            # a basic web crawler using selenium 
            search_web(input) 
            return

        elif "who are you" in input or "define yourself" in input: 
            speak = '''I am Your True Friend.'''
            assistant_speaks(speak) 
            return
        elif "what is your name" in input:
            speak = '''My name is Zayikaa.'''
            assistant_speaks(speak)
            return
        
        
        elif "what can you do" in input or "what is your function" in input or "What is your work" in input or "what you can do for me" in input:
                    speak = '''I will help you to talk to anybody.
                        But Right now as I am at initial stage and 
                        I will just help you to talk to puneet only.'''
                    assistant_speaks(speak)
                    return

        elif "who made you" in input or "created you" in input: 
            speak = "I have been created by PSR team of PIS MAJOR project."
            assistant_speaks(speak) 
            return

        elif "can i talk to puneet" in input.lower() or "call puneet" in input.lower() or "i want to talk to puneet" in input.lower():# just 
            speak = """Yeah, sure. Now you are going to talk to puneet."""
            image.show()
            assistant_speaks(speak)
            while True:
                sear = talk_audio()
                if sear in puneet:
                    speak = puneet[sear]
                    assistant_speaks(speak)
                elif(sear == "hi bro"):
                    assistant_speaks(sear)
                elif(sear == "chup kar yaar") or (sear == "ok bye") or (sear == "exit") or (sear == "theek hai yaar"):
                    speak = "Ok bye" + str(name)
                    assistant_speaks(speak)
                    break
                else:
                    assistant_speaks("I didn't understand my friend.Can you please repeat that?")
            return


        elif "calculate" in input.lower(): 
			
            # write your wolframalpha app_id here 
            app_id = "WOLFRAMALPHA_APP_ID"
            client = wolframalpha.Client(app_id) 

            indx = input.lower().split().index('calculate') 
            query = input.split()[indx + 1:] 
            res = client.query(' '.join(query)) 
            answer = next(res.results).text 
            assistant_speaks("The answer is " + answer) 
            return

        elif 'open' in input: 
			
            # another function to open 
            # different application availaible 
            open_application(input.lower()) 
            return

        else: 

            assistant_speaks("I can search the web for you, Do you want to continue?") 
            ans = get_audio() 
            if 'yes' in str(ans) or 'yeah' in str(ans): 
                search_web(input) 
            else: 
                return
    except : 

        assistant_speaks("I don't understand, I can search the web for you, Do you want to continue?") 
        ans = get_audio() 
        if 'yes' in str(ans) or 'yeah' in str(ans): 
            search_web(input) 


# Driver Code 
if __name__ == "__main__": 
    if name == "Unknown":
        assistant_speaks("What's your name, my friend?") 
        name = get_audio()
        assistant_speaks("Hello, " + name + '.') 
    else:
        assistant_speaks("Hello, " + name + '.') 
	
    while(1): 

        assistant_speaks("How can I help you?") 
        text = get_audio().lower() 

        if text == 0: 
            continue

        if "exit" in str(text) or "bye" in str(text) or "sleep" in str(text): 
            assistant_speaks("Ok bye, "+ name+'.') 
            break

        # calling process text to process the query 
        process_text(text)
#image.kill()
















